{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSIS549_HW1_newswires (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danjingrong/Exploratory-Analysis-of-the-Little-Review/blob/danjingrong-patch-1/MSIS549_HW1_newswires_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0lDkFZq3ohI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "16b53a31-d2a7-415b-db98-3ea04a47c6a4"
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import keras\n",
        "keras.__version__\n",
        "\n",
        "!pip install numpy==1.16.1\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/57/07c49e1a6d2706fb7336b3fb11dd285c1e96535c80833d7524f002f57086/numpy-1.16.1-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 40.0MB/s \n",
            "\u001b[31mERROR: lucid 0.3.10 requires umap-learn, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.2 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.18.0 has requirement numpy>=1.17, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2.1 has requirement numpy>=1.17, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu5jf9gW3ohR"
      },
      "source": [
        "# Classifying newswires: a multi-class classification example\n",
        "\n",
        "In this homework, we will build a network to classify Reuters newswires into 46 different mutually-exclusive topics. Since we have many \n",
        "classes, this problem is an instance of \"multi-class classification\", and since each data point should be classified into only one \n",
        "category, the problem is more specifically an instance of \"single-label, multi-class classification\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-s49gXW3ohT"
      },
      "source": [
        "## The Reuters dataset\n",
        "\n",
        "\n",
        "We will be working with the _Reuters dataset_, a set of short newswires and their topics, published by Reuters in 1986. It's a very simple, \n",
        "widely used toy dataset for text classification. There are 46 different topics; some topics are more represented than others, but each \n",
        "topic has at least 10 examples in the training set.\n",
        "\n",
        "Like IMDB and MNIST, the Reuters dataset comes packaged as part of Keras. Let's take a look right away:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjSiBNZS3ohU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d22a5cb-1f83-4a75-c15e-a0e4413ba889"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VRrIjNI3ohX"
      },
      "source": [
        "\n",
        "Like with the IMDB dataset, the argument `num_words=10000` restricts the data to the 10,000 most frequently occurring words found in the \n",
        "data.\n",
        "\n",
        "We have 8,982 training examples and 2,246 test examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMdiLzvF3ohf"
      },
      "source": [
        "As with the IMDB reviews, each example is a list of integers (word indices):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QriVgMSe3ohg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1f72d7-f9e6-4ee0-b4ad-f2a7dfcda1f2"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 2,\n",
              " 8,\n",
              " 43,\n",
              " 10,\n",
              " 447,\n",
              " 5,\n",
              " 25,\n",
              " 207,\n",
              " 270,\n",
              " 5,\n",
              " 3095,\n",
              " 111,\n",
              " 16,\n",
              " 369,\n",
              " 186,\n",
              " 90,\n",
              " 67,\n",
              " 7,\n",
              " 89,\n",
              " 5,\n",
              " 19,\n",
              " 102,\n",
              " 6,\n",
              " 19,\n",
              " 124,\n",
              " 15,\n",
              " 90,\n",
              " 67,\n",
              " 84,\n",
              " 22,\n",
              " 482,\n",
              " 26,\n",
              " 7,\n",
              " 48,\n",
              " 4,\n",
              " 49,\n",
              " 8,\n",
              " 864,\n",
              " 39,\n",
              " 209,\n",
              " 154,\n",
              " 6,\n",
              " 151,\n",
              " 6,\n",
              " 83,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 155,\n",
              " 11,\n",
              " 15,\n",
              " 7,\n",
              " 48,\n",
              " 9,\n",
              " 4579,\n",
              " 1005,\n",
              " 504,\n",
              " 6,\n",
              " 258,\n",
              " 6,\n",
              " 272,\n",
              " 11,\n",
              " 15,\n",
              " 22,\n",
              " 134,\n",
              " 44,\n",
              " 11,\n",
              " 15,\n",
              " 16,\n",
              " 8,\n",
              " 197,\n",
              " 1245,\n",
              " 90,\n",
              " 67,\n",
              " 52,\n",
              " 29,\n",
              " 209,\n",
              " 30,\n",
              " 32,\n",
              " 132,\n",
              " 6,\n",
              " 109,\n",
              " 15,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIvaOPin3ohj"
      },
      "source": [
        "Here's how you can decode it back to words, in case you are curious:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZg6ME3Y3ohk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43d3338-e456-4e34-f8c8-137c44900d4a"
      },
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# Note that our indices were offset by 3\n",
        "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
        "\n",
        "print(\"The decoded text:\" + decoded_newswire)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "The decoded text:? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yntI1JS33oho"
      },
      "source": [
        "The label associated with an example is an integer between 0 and 45: a topic index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swMqUzqz3ohq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e609052c-d80a-4a09-e9fc-68fc3d86e271"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsLn40NK3oht"
      },
      "source": [
        "## Preparing the data\n",
        "\n",
        "We can vectorize the data with the exact same code as in our previous example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDol7z_43ohu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# Our vectorized training data\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# Our vectorized test data\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pte7Qr63ohv"
      },
      "source": [
        "\n",
        "Use \"one-hot\" encoding to vectorize the labels. One-hot encoding is a widely used format for categorical data, also called \"categorical encoding\". In our case, one-hot encoding of our labels consists in embedding each label as an all-zero vector with a 1 in the place of the label index. Note that there is a built-in way to do this in Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO_SmjOD3ohy"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMvTFcc03ohz"
      },
      "source": [
        "## Building our network\n",
        "\n",
        "\n",
        "This topic classification problem looks very similar to our previous movie review classification problem: in both cases, we are trying to \n",
        "classify short snippets of text. There is however a new constraint here: the number of output classes has gone from 2 to 46, i.e. the \n",
        "dimensionality of the output space is much larger. \n",
        "\n",
        "In a stack of `Dense` layers like what we were using, each layer can only access information present in the output of the previous layer. \n",
        "If one layer drops some information relevant to the classification problem, this information can never be recovered by later layers: each \n",
        "layer can potentially become an \"information bottleneck\". In our previous example, we were using 16-dimensional intermediate layers, but a \n",
        "16-dimensional space may be too limited to learn to separate 46 different classes: such small layers may act as information bottlenecks, \n",
        "permanently dropping relevant information.\n",
        "\n",
        "For this reason we will use larger layers. Let's go with 64 units:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhwRTjx3ohz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e40e066-c207-49cf-c900-51c97c0c5448"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# TODO: specify the architecture of the model.\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                640064    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 46)                2990      \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 647,214\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Aj666N3oh1"
      },
      "source": [
        "\n",
        "There are two other things you should note about this architecture:\n",
        "\n",
        "* We are ending the network with a `Dense` layer of size 46. This means that for each input sample, our network will output a \n",
        "46-dimensional vector. Each entry in this vector (each dimension) will encode a different output class.\n",
        "* The last layer uses a `softmax` activation. You have already seen this pattern in the MNIST example. It means that the network will \n",
        "output a _probability distribution_ over the 46 different output classes, i.e. for every input sample, the network will produce a \n",
        "46-dimensional output vector where `output[i]` is the probability that the sample belongs to class `i`. The 46 scores will sum to 1.\n",
        "\n",
        "The best loss function to use in this case is `categorical_crossentropy`. It measures the distance between two probability distributions: \n",
        "in our case, between the probability distribution output by our network, and the true distribution of the labels. By minimizing the \n",
        "distance between these two distributions, we train our network to output something as close as possible to the true labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhmA6zNZ3oh1"
      },
      "source": [
        "# TODO: compile the model you just built\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.categorical_crossentropy,\n",
        "              metrics=[metrics.categorical_accuracy])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGB_cp8B3oh2"
      },
      "source": [
        "## Validating our approach\n",
        "\n",
        "Let's set apart 1,000 samples in our training data to use as a validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3eyzgOA3oh2"
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFUZkt43oh3"
      },
      "source": [
        "Now let's train our network for 20 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM57jbod3oh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbb7059-dc33-40be-aabc-7e42eef45bae"
      },
      "source": [
        "# TODO: fit the model with the training dataset and provide validation data \n",
        "# to help check overfitting\n",
        "history = history = model.fit(partial_x_train, partial_y_train, epochs=20, \n",
        "                              batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 2s 86ms/step - loss: 3.1072 - categorical_accuracy: 0.4131 - val_loss: 1.6953 - val_categorical_accuracy: 0.6500\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 1.4711 - categorical_accuracy: 0.6983 - val_loss: 1.2748 - val_categorical_accuracy: 0.7130\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 1.0754 - categorical_accuracy: 0.7705 - val_loss: 1.1011 - val_categorical_accuracy: 0.7630\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.8363 - categorical_accuracy: 0.8240 - val_loss: 1.0189 - val_categorical_accuracy: 0.7830\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.6503 - categorical_accuracy: 0.8616 - val_loss: 0.9745 - val_categorical_accuracy: 0.8050\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.5188 - categorical_accuracy: 0.8942 - val_loss: 0.9310 - val_categorical_accuracy: 0.8050\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.4139 - categorical_accuracy: 0.9187 - val_loss: 0.8950 - val_categorical_accuracy: 0.8160\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.3321 - categorical_accuracy: 0.9296 - val_loss: 0.8764 - val_categorical_accuracy: 0.8210\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.2840 - categorical_accuracy: 0.9404 - val_loss: 0.8848 - val_categorical_accuracy: 0.8190\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.2232 - categorical_accuracy: 0.9484 - val_loss: 0.9179 - val_categorical_accuracy: 0.8110\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1975 - categorical_accuracy: 0.9530 - val_loss: 0.9320 - val_categorical_accuracy: 0.8150\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1667 - categorical_accuracy: 0.9548 - val_loss: 0.9153 - val_categorical_accuracy: 0.8120\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1509 - categorical_accuracy: 0.9590 - val_loss: 0.9666 - val_categorical_accuracy: 0.8090\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1378 - categorical_accuracy: 0.9590 - val_loss: 0.9724 - val_categorical_accuracy: 0.8160\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1254 - categorical_accuracy: 0.9629 - val_loss: 0.9694 - val_categorical_accuracy: 0.8220\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.1190 - categorical_accuracy: 0.9597 - val_loss: 0.9926 - val_categorical_accuracy: 0.8150\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1092 - categorical_accuracy: 0.9646 - val_loss: 1.0102 - val_categorical_accuracy: 0.8130\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1107 - categorical_accuracy: 0.9610 - val_loss: 1.0360 - val_categorical_accuracy: 0.8060\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.1113 - categorical_accuracy: 0.9610 - val_loss: 1.0407 - val_categorical_accuracy: 0.8090\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0971 - categorical_accuracy: 0.9636 - val_loss: 1.0336 - val_categorical_accuracy: 0.8090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq5P0gWQ3oh5"
      },
      "source": [
        "Let's display its loss and accuracy curves to help identify when it starts to overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRFHE0U3oh5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "e1f63bcb-0150-4c0e-b478-7ea2436b92ea"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO: plot the model loss on both training and validation data. \n",
        "\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7b3173d4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M69rtt143oh6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "57804761-35a5-4151-aa72-0da69e67aebb"
      },
      "source": [
        "# TODO: plot prediction accuracy on both training and validation data. \n",
        "plt.clf()\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUarkgZd3oh7"
      },
      "source": [
        "It seems that the network starts overfitting after certain epochs. Let's train a new network from scratch for fewer epochs before it starts overfitting, then let's evaluate it on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IciZ2dMP3oh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e501b11f-7468-4231-d7d0-0a0d20b74d57"
      },
      "source": [
        "# TODO: retrain the model with the fewer epoches to avoid overfitting\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit( partial_x_train, partial_y_train, epochs=9, batch_size=512, validation_data=(x_val, y_val))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/9\n",
            "16/16 [==============================] - 2s 64ms/step - loss: 3.0846 - accuracy: 0.4250 - val_loss: 1.7219 - val_accuracy: 0.6320\n",
            "Epoch 2/9\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 1.4725 - accuracy: 0.6990 - val_loss: 1.2784 - val_accuracy: 0.7160\n",
            "Epoch 3/9\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 1.0713 - accuracy: 0.7677 - val_loss: 1.1079 - val_accuracy: 0.7440\n",
            "Epoch 4/9\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.8319 - accuracy: 0.8164 - val_loss: 1.0311 - val_accuracy: 0.7800\n",
            "Epoch 5/9\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.6597 - accuracy: 0.8571 - val_loss: 0.9673 - val_accuracy: 0.8010\n",
            "Epoch 6/9\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.5249 - accuracy: 0.8953 - val_loss: 0.9472 - val_accuracy: 0.8030\n",
            "Epoch 7/9\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.4194 - accuracy: 0.9161 - val_loss: 0.8914 - val_accuracy: 0.8120\n",
            "Epoch 8/9\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.3300 - accuracy: 0.9306 - val_loss: 0.9408 - val_accuracy: 0.8000\n",
            "Epoch 9/9\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.2862 - accuracy: 0.9385 - val_loss: 0.8746 - val_accuracy: 0.8240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b310a4350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ3VcXyx3oh_"
      },
      "source": [
        "\n",
        "Your model should reach an accuracy of ~78%. With a balanced binary classification problem, the accuracy reached by a purely random classifier \n",
        "would be 50%, but in our case it is closer to 19%, so our results seem pretty good, at least when compared to a random baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEzjb1m33oiA"
      },
      "source": [
        "## Generating predictions on new data\n",
        "\n",
        "We can verify that the `predict` method of our model instance returns a probability distribution over all 46 topics. Let's generate topic \n",
        "predictions for all of the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIuTWvUq3oiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a48ec4-e69d-4500-d9cf-b2ac0d74468b"
      },
      "source": [
        "# TODO: use the learnt neural network to make a prediction on \n",
        "# the test data \n",
        "predict = model.predict(x_test)\n",
        "predict"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6132233e-04, 2.0871504e-04, 8.6506552e-05, ..., 4.7268692e-05,\n",
              "        5.8613000e-06, 3.0824158e-05],\n",
              "       [2.1534381e-03, 1.9516472e-02, 3.2937001e-03, ..., 1.4948123e-04,\n",
              "        7.0136186e-05, 1.5208608e-04],\n",
              "       [1.1057208e-03, 8.5485089e-01, 1.5231634e-03, ..., 2.4541019e-04,\n",
              "        7.1626651e-04, 1.3621645e-04],\n",
              "       ...,\n",
              "       [5.7331672e-05, 2.8260413e-04, 2.3189552e-05, ..., 1.8709647e-05,\n",
              "        9.5898777e-06, 2.0234465e-05],\n",
              "       [5.8121667e-03, 6.3889541e-02, 1.0955584e-03, ..., 8.9817750e-04,\n",
              "        9.5403922e-04, 9.8336150e-04],\n",
              "       [5.0280418e-04, 5.8142066e-01, 9.9310242e-03, ..., 4.8709495e-05,\n",
              "        1.8905428e-04, 8.0113932e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1LzmGXx3oiB"
      },
      "source": [
        "Each entry in `predictions` is a vector of length 46. **The** largest entry is the predicted class, i.e. the class with the highest probability:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3RyKAsw3oiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4a925c-0563-4ecc-b2dc-25461cf34e45"
      },
      "source": [
        "# TODO: evaluate model performan in terms of accuracy on prediction against the ground truth.\n",
        "test_loss, test_acc=model.evaluate(x_test,predict)\n",
        "predict.shape\n",
        "print('test_acc', test_acc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 1.0000\n",
            "test_acc 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw3GlSYG3oiH"
      },
      "source": [
        "## On the importance of having sufficiently large intermediate layers\n",
        "\n",
        "\n",
        "We mentioned earlier that since our final outputs were 46-dimensional, we should avoid intermediate layers with much less than 46 hidden \n",
        "units. Now let's try to see what happens when we introduce an information bottleneck by having intermediate layers significantly less than \n",
        "46-dimensional, e.g. 4-dimensional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emfKokRe3oiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d10016a-a107-43fd-bac7-4356ddba5bbb"
      },
      "source": [
        "# TODO: build a neural network with 4 neuron units in the hidden layer with the validation data \n",
        "# and evaluate its performance on the test data.\n",
        "model_2 = models.Sequential()\n",
        "model_2.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model_2.add(layers.Dense(4, activation='relu'))\n",
        "model_2.add(layers.Dense(46, activation='softmax')) \n",
        "\n",
        "model_2.compile( optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_2.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 3.7846 - accuracy: 0.0255 - val_loss: 3.6046 - val_accuracy: 0.0610\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 3.5199 - accuracy: 0.0591 - val_loss: 3.3353 - val_accuracy: 0.2270\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 3.2025 - accuracy: 0.2635 - val_loss: 3.0659 - val_accuracy: 0.3000\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 2.8561 - accuracy: 0.3231 - val_loss: 2.7634 - val_accuracy: 0.3050\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 2.5394 - accuracy: 0.3323 - val_loss: 2.4826 - val_accuracy: 0.3170\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 2.2247 - accuracy: 0.3479 - val_loss: 2.2047 - val_accuracy: 0.5850\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.8611 - accuracy: 0.6583 - val_loss: 1.9043 - val_accuracy: 0.6510\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.5303 - accuracy: 0.7085 - val_loss: 1.6699 - val_accuracy: 0.6720\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.2854 - accuracy: 0.7160 - val_loss: 1.5377 - val_accuracy: 0.6700\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 1.1464 - accuracy: 0.7251 - val_loss: 1.4811 - val_accuracy: 0.6710\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.0665 - accuracy: 0.7320 - val_loss: 1.4519 - val_accuracy: 0.6640\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.9806 - accuracy: 0.7479 - val_loss: 1.4280 - val_accuracy: 0.6720\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.9578 - accuracy: 0.7591 - val_loss: 1.4350 - val_accuracy: 0.6870\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.8745 - accuracy: 0.7723 - val_loss: 1.4296 - val_accuracy: 0.6830\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.8715 - accuracy: 0.7701 - val_loss: 1.4359 - val_accuracy: 0.6940\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.8018 - accuracy: 0.7898 - val_loss: 1.4340 - val_accuracy: 0.6920\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.7914 - accuracy: 0.7944 - val_loss: 1.4579 - val_accuracy: 0.6940\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.7369 - accuracy: 0.8012 - val_loss: 1.4717 - val_accuracy: 0.6920\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.7193 - accuracy: 0.8019 - val_loss: 1.4670 - val_accuracy: 0.6970\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.6619 - accuracy: 0.8202 - val_loss: 1.4996 - val_accuracy: 0.6970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b31608410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6wV_AR23oiI"
      },
      "source": [
        "\n",
        "You should see the model performance drop. This drop is mostly due to the fact that we are now trying to compress a lot of information (enough information to recover the separation hyperplanes of 46 classes) into an intermediate space that is too low-dimensional. The network is able to cram _most_ of the necessary information into these 8-dimensional representations, but not all of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bFLuR8b3oiI"
      },
      "source": [
        "## Try using larger or smaller hidden layers: 32 units, and 128 units, and see if you will be able to improve the model performance on the test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1v7pFMGrEik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a07a5bf-846a-43a1-dfad-1fe5f2530c86"
      },
      "source": [
        "# TODO: Try using larger or smaller hidden layers: 32 units, and 128 units\n",
        "model_3 = models.Sequential()\n",
        "model_3.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model_3.add(layers.Dense(32, activation='relu'))\n",
        "model_3.add(layers.Dense(46, activation='softmax')) \n",
        "\n",
        "model_3.compile( optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_3.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 3.2447 - accuracy: 0.3500 - val_loss: 2.0213 - val_accuracy: 0.6180\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 1.7383 - accuracy: 0.6628 - val_loss: 1.4737 - val_accuracy: 0.6840\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 1.2470 - accuracy: 0.7447 - val_loss: 1.2491 - val_accuracy: 0.7280\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.9674 - accuracy: 0.7949 - val_loss: 1.1148 - val_accuracy: 0.7590\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.8016 - accuracy: 0.8235 - val_loss: 1.0421 - val_accuracy: 0.7760\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.6599 - accuracy: 0.8573 - val_loss: 1.0012 - val_accuracy: 0.7840\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.5469 - accuracy: 0.8869 - val_loss: 0.9610 - val_accuracy: 0.7880\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.4562 - accuracy: 0.9057 - val_loss: 0.9276 - val_accuracy: 0.8080\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.3807 - accuracy: 0.9205 - val_loss: 0.9196 - val_accuracy: 0.8050\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.3163 - accuracy: 0.9337 - val_loss: 0.9192 - val_accuracy: 0.8070\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.2788 - accuracy: 0.9405 - val_loss: 0.9200 - val_accuracy: 0.8100\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.2388 - accuracy: 0.9488 - val_loss: 0.9305 - val_accuracy: 0.8100\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.2000 - accuracy: 0.9529 - val_loss: 0.9415 - val_accuracy: 0.8140\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.1783 - accuracy: 0.9550 - val_loss: 0.9645 - val_accuracy: 0.8100\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1550 - accuracy: 0.9602 - val_loss: 1.0009 - val_accuracy: 0.8120\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1442 - accuracy: 0.9583 - val_loss: 1.0096 - val_accuracy: 0.8130\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1492 - accuracy: 0.9561 - val_loss: 1.0111 - val_accuracy: 0.8100\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.1355 - accuracy: 0.9562 - val_loss: 1.0240 - val_accuracy: 0.8150\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.1212 - accuracy: 0.9619 - val_loss: 1.0528 - val_accuracy: 0.7990\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.1166 - accuracy: 0.9603 - val_loss: 1.0572 - val_accuracy: 0.8070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b31af6bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zioV9x5fzDUu",
        "outputId": "65851dd2-0416-40f8-a288-e473b6992d95"
      },
      "source": [
        "result = model_3.evaluate(x_test,one_hot_test_labels)\n",
        "print(result)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 3ms/step - loss: 1.2194 - accuracy: 0.7801\n",
            "[1.2193691730499268, 0.780053436756134]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpemuu7AzRep",
        "outputId": "22df449c-29a2-420d-c0ff-24ccfdb123f9"
      },
      "source": [
        "model_4 = models.Sequential()\n",
        "model_4.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model_4.add(layers.Dense(128, activation='relu'))\n",
        "model_4.add(layers.Dense(46, activation='softmax')) \n",
        "\n",
        "model_4.compile( optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_4.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 2s 64ms/step - loss: 3.0207 - accuracy: 0.4098 - val_loss: 1.5911 - val_accuracy: 0.6300\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 1.3955 - accuracy: 0.7005 - val_loss: 1.2705 - val_accuracy: 0.7250\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 1.0143 - accuracy: 0.7839 - val_loss: 1.0837 - val_accuracy: 0.7610\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.7792 - accuracy: 0.8300 - val_loss: 1.0019 - val_accuracy: 0.7850\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.6189 - accuracy: 0.8676 - val_loss: 0.9508 - val_accuracy: 0.7930\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.4583 - accuracy: 0.9037 - val_loss: 0.9794 - val_accuracy: 0.7890\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.3538 - accuracy: 0.9245 - val_loss: 0.9068 - val_accuracy: 0.8070\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.2986 - accuracy: 0.9368 - val_loss: 0.8877 - val_accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.2373 - accuracy: 0.9448 - val_loss: 0.8955 - val_accuracy: 0.8050\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.1940 - accuracy: 0.9516 - val_loss: 0.8923 - val_accuracy: 0.8140\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.1656 - accuracy: 0.9572 - val_loss: 0.9074 - val_accuracy: 0.8210\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.1434 - accuracy: 0.9588 - val_loss: 0.9318 - val_accuracy: 0.8170\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1381 - accuracy: 0.9578 - val_loss: 0.9838 - val_accuracy: 0.8190\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.1247 - accuracy: 0.9612 - val_loss: 0.9995 - val_accuracy: 0.8000\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.1199 - accuracy: 0.9621 - val_loss: 1.0318 - val_accuracy: 0.7950\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.1140 - accuracy: 0.9625 - val_loss: 1.0427 - val_accuracy: 0.8120\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.1082 - accuracy: 0.9622 - val_loss: 1.0543 - val_accuracy: 0.7950\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.1120 - accuracy: 0.9600 - val_loss: 1.0764 - val_accuracy: 0.7980\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.1022 - accuracy: 0.9604 - val_loss: 1.0590 - val_accuracy: 0.8080\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0994 - accuracy: 0.9624 - val_loss: 1.1478 - val_accuracy: 0.7870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b316bb510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4hila-VzW4x",
        "outputId": "348e30ab-8065-42bd-ae95-023034aa26a4"
      },
      "source": [
        "result = model_4.evaluate(x_test,one_hot_test_labels)\n",
        "print(result)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 3ms/step - loss: 1.2711 - accuracy: 0.7743\n",
            "[1.2710927724838257, 0.7742653489112854]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ1JPiTErD7X"
      },
      "source": [
        "\n",
        "## We were using two hidden layers. Now try to use a single hidden layer, or three hidden layers, and see if you will be able to improve the model performance on the test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zukIClyrh3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6a3199-a9b4-40cc-b839-8f9dd56ed8f8"
      },
      "source": [
        "# TODO: Try to use a single hidden layer, or three hidden layers\n",
        "model_5 = models.Sequential()\n",
        "model_5.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model_5.add(layers.Dense(46, activation='softmax')) \n",
        "\n",
        "model_5.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_5.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 3.0742 - accuracy: 0.4555 - val_loss: 1.8246 - val_accuracy: 0.6650\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 1.5827 - accuracy: 0.7162 - val_loss: 1.3454 - val_accuracy: 0.7240\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 1.1141 - accuracy: 0.7813 - val_loss: 1.1341 - val_accuracy: 0.7670\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.8377 - accuracy: 0.8335 - val_loss: 1.0167 - val_accuracy: 0.7900\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.6926 - accuracy: 0.8616 - val_loss: 0.9412 - val_accuracy: 0.8040\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.5642 - accuracy: 0.8871 - val_loss: 0.8925 - val_accuracy: 0.8160\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.4621 - accuracy: 0.9119 - val_loss: 0.8479 - val_accuracy: 0.8230\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.3800 - accuracy: 0.9247 - val_loss: 0.8376 - val_accuracy: 0.8240\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.3160 - accuracy: 0.9384 - val_loss: 0.8258 - val_accuracy: 0.8250\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.2584 - accuracy: 0.9483 - val_loss: 0.8200 - val_accuracy: 0.8270\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.2211 - accuracy: 0.9513 - val_loss: 0.8320 - val_accuracy: 0.8240\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1951 - accuracy: 0.9521 - val_loss: 0.8221 - val_accuracy: 0.8300\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1708 - accuracy: 0.9571 - val_loss: 0.8336 - val_accuracy: 0.8240\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1564 - accuracy: 0.9571 - val_loss: 0.8488 - val_accuracy: 0.8290\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1424 - accuracy: 0.9566 - val_loss: 0.8673 - val_accuracy: 0.8220\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.1327 - accuracy: 0.9591 - val_loss: 0.8767 - val_accuracy: 0.8240\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1230 - accuracy: 0.9613 - val_loss: 0.8998 - val_accuracy: 0.8170\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.1165 - accuracy: 0.9597 - val_loss: 0.8962 - val_accuracy: 0.8250\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.1082 - accuracy: 0.9637 - val_loss: 0.9095 - val_accuracy: 0.8200\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0966 - accuracy: 0.9639 - val_loss: 0.9137 - val_accuracy: 0.8190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b31a19c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF2ntMyqziD2",
        "outputId": "26de4436-f025-4dde-b82d-4e2d5828a7b5"
      },
      "source": [
        "result = model_5.evaluate(x_test,one_hot_test_labels)\n",
        "print(result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 3ms/step - loss: 1.0413 - accuracy: 0.7943\n",
            "[1.0413033962249756, 0.7943009734153748]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gldwCoKB3oiI"
      },
      "source": [
        "## Wrapping up\n",
        "\n",
        "\n",
        "Here's what you should take away from this example:\n",
        "\n",
        "* If you are trying to classify data points between N classes, your network should end with a `Dense` layer of size N.\n",
        "* In a single-label, multi-class classification problem, your network should end with a `softmax` activation, so that it will output a \n",
        "probability distribution over the N output classes.\n",
        "* _Categorical crossentropy_ is almost always the loss function you should use for such problems. It minimizes the distance between the \n",
        "probability distributions output by the network, and the true distribution of the targets.\n",
        "* There are two ways to handle labels in multi-class classification:\n",
        "    ** Encoding the labels via \"categorical encoding\" (also known as \"one-hot encoding\") and using `categorical_crossentropy` as your loss \n",
        "function.\n",
        "    ** Encoding the labels as integers and using the `sparse_categorical_crossentropy` loss function.\n",
        "* If you need to classify data into a large number of categories, then you should avoid creating information bottlenecks in your network by having \n",
        "intermediate layers that are too small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKekl-HuGXiU"
      },
      "source": [
        "## Bonus Point\n",
        "Can you think of other methods to further improve the model performance? Code it up and evaluate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38I30otcrO-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "367e6f5f-b64f-431d-fa41-a3e4b8ea90f3"
      },
      "source": [
        "#Reducing the batch size\n",
        "model_b = models.Sequential()\n",
        "model_b.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model_b.add(layers.Dense(46, activation='relu'))\n",
        "model_b.add(layers.Dense(46, activation='softmax')) \n",
        "\n",
        "model_b.compile( optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_b.fit(partial_x_train, partial_y_train, epochs=20, batch_size=64, validation_data=(x_val, y_val))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 2.3087 - accuracy: 0.5475 - val_loss: 1.1474 - val_accuracy: 0.7400\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.9134 - accuracy: 0.8027 - val_loss: 0.9507 - val_accuracy: 0.8090\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.5777 - accuracy: 0.8755 - val_loss: 0.8629 - val_accuracy: 0.8180\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.3849 - accuracy: 0.9194 - val_loss: 0.8691 - val_accuracy: 0.8240\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2752 - accuracy: 0.9365 - val_loss: 0.8722 - val_accuracy: 0.8340\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2064 - accuracy: 0.9535 - val_loss: 0.9362 - val_accuracy: 0.8160\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1735 - accuracy: 0.9536 - val_loss: 0.9847 - val_accuracy: 0.8160\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1523 - accuracy: 0.9543 - val_loss: 0.9989 - val_accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1393 - accuracy: 0.9594 - val_loss: 1.0351 - val_accuracy: 0.8100\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1296 - accuracy: 0.9556 - val_loss: 1.0985 - val_accuracy: 0.8050\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1105 - accuracy: 0.9635 - val_loss: 1.3320 - val_accuracy: 0.7810\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.1085 - accuracy: 0.9611 - val_loss: 1.2342 - val_accuracy: 0.8030\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1084 - accuracy: 0.9601 - val_loss: 1.2402 - val_accuracy: 0.7930\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0984 - accuracy: 0.9622 - val_loss: 1.2701 - val_accuracy: 0.8030\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1072 - accuracy: 0.9572 - val_loss: 1.2832 - val_accuracy: 0.7940\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0942 - accuracy: 0.9623 - val_loss: 1.4158 - val_accuracy: 0.7900\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0836 - accuracy: 0.9643 - val_loss: 1.4899 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0874 - accuracy: 0.9632 - val_loss: 1.5163 - val_accuracy: 0.7970\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0845 - accuracy: 0.9597 - val_loss: 1.5364 - val_accuracy: 0.7880\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.0852 - accuracy: 0.9628 - val_loss: 1.6543 - val_accuracy: 0.7900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7b312b7050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_XLLwAxzswA",
        "outputId": "33c3f33b-7b37-40bb-e379-2cbe15809db1"
      },
      "source": [
        "result = model_b.evaluate(x_test,one_hot_test_labels)\n",
        "print(result)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 3ms/step - loss: 1.9779 - accuracy: 0.7756\n",
            "[1.9779452085494995, 0.7756010890007019]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "gEpxKJ7jzu4T",
        "outputId": "018420b8-7803-4c10-b2cc-88219c657e39"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "batch = range(64, len(acc) +64)\n",
        "\n",
        "\n",
        "plt.plot(batch, loss, 'bo', label='Training loss')\n",
        "plt.plot(batch, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Batch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7b30c86dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7CGM-0QrOrp"
      },
      "source": [
        "# End of HW1"
      ]
    }
  ]
}